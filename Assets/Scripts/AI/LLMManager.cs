// Auto-generated by CursedPortal AI Spec v1.0
// Source: Module M3

using UnityEngine;
using System.IO;
using System.Collections;

/// <summary>
/// Central manager for LLM-based Poe spirit interactions.
/// Handles spirit summoning, context building, and response processing.
/// </summary>
public class LLMManager : MonoBehaviour
{
    public static LLMManager Instance { get; private set; }

    [Header("LLM Configuration")]
    [SerializeField] private string llmEndpoint = "http://localhost:8080/completion";
    [SerializeField] private int maxContextLength = 4000;
    [SerializeField] private float temperature = 0.8f;
    [SerializeField] private int maxTokens = 256;

    [Header("Current State")]
    public string ActiveSpirit { get; private set; }
    public string ActiveStory { get; private set; }

    // Spirit profile data structure
    [System.Serializable]
    public class SpiritProfile
    {
        public string story;
        public string prompt;
    }

    [System.Serializable]
    private class SpiritProfiles
    {
        public SpiritProfile Raven;
        public SpiritProfile Narrator;
        public SpiritProfile Usher;
    }

    // Cached profiles
    private SpiritProfiles profiles;
    private bool profilesLoaded = false;

    // Cached story texts to avoid blocking I/O during gameplay
    private System.Collections.Generic.Dictionary<string, string> cachedStories =
        new System.Collections.Generic.Dictionary<string, string>();

    private void Awake()
    {
        // Singleton pattern with persistence
        if (Instance == null)
        {
            Instance = this;
            DontDestroyOnLoad(gameObject);
        }
        else
        {
            Destroy(gameObject);
            return;
        }
    }

    private void Start()
    {
        LoadSpiritProfiles();
        // Pre-load story files in background to avoid blocking during gameplay
        StartCoroutine(PreloadStoryFiles());
    }

    /// <summary>
    /// Pre-loads all story files into cache during startup.
    /// </summary>
    private IEnumerator PreloadStoryFiles()
    {
        string[] storyFiles = { "raven.txt", "tell-tale-heart.txt", "usher.txt" };

        foreach (string storyFile in storyFiles)
        {
            string storyPath = Path.Combine(Application.streamingAssetsPath, "PoeStories", storyFile);

            if (File.Exists(storyPath))
            {
                // Use a background thread for file I/O
                string fileContent = null;
                bool loadComplete = false;

                System.Threading.ThreadPool.QueueUserWorkItem(_ =>
                {
                    try
                    {
                        fileContent = File.ReadAllText(storyPath);
                    }
                    catch (System.Exception e)
                    {
                        Debug.LogWarning($"[LLMManager] Failed to preload {storyFile}: {e.Message}");
                    }
                    loadComplete = true;
                });

                // Wait for background load to complete
                while (!loadComplete)
                {
                    yield return null;
                }

                if (!string.IsNullOrEmpty(fileContent))
                {
                    // Truncate to max context length
                    int truncateLength = Mathf.Min(fileContent.Length, maxContextLength);
                    cachedStories[storyFile] = fileContent.Substring(0, truncateLength);
                    Debug.Log($"[LLMManager] Pre-loaded story: {storyFile}");
                }
            }

            // Yield between files to prevent frame hitches
            yield return null;
        }

        Debug.Log($"[LLMManager] Story preloading complete. Cached {cachedStories.Count} stories.");
    }

    /// <summary>
    /// Loads spirit profiles from JSON file.
    /// </summary>
    private void LoadSpiritProfiles()
    {
        string jsonPath = Path.Combine(Application.streamingAssetsPath, "SpiritProfiles", "poe_spirits.json");

        if (File.Exists(jsonPath))
        {
            string json = File.ReadAllText(jsonPath);
            profiles = JsonUtility.FromJson<SpiritProfiles>(json);
            profilesLoaded = true;
            Debug.Log("[LLMManager] Spirit profiles loaded successfully.");
        }
        else
        {
            Debug.LogError($"[LLMManager] Spirit profiles not found at: {jsonPath}");
        }
    }

    /// <summary>
    /// Gets a spirit profile by key name.
    /// </summary>
    private SpiritProfile GetProfile(string spiritKey)
    {
        if (!profilesLoaded)
        {
            LoadSpiritProfiles();
        }

        return spiritKey switch
        {
            "Raven" => profiles?.Raven,
            "Narrator" => profiles?.Narrator,
            "Usher" => profiles?.Usher,
            _ => profiles?.Raven // Default to Raven
        };
    }

    /// <summary>
    /// Summons a spirit and initiates conversation.
    /// </summary>
    /// <param name="spiritKey">The spirit to summon (Raven, Narrator, Usher)</param>
    public void SummonSpirit(string spiritKey)
    {
        SpiritProfile profile = GetProfile(spiritKey);
        if (profile == null)
        {
            Debug.LogError($"[LLMManager] Spirit profile not found: {spiritKey}");
            return;
        }

        ActiveSpirit = spiritKey;
        ActiveStory = profile.story;

        Debug.Log($"[LLMManager] Summoning spirit: {spiritKey}");

        // Build context with story and system prompt
        string context = BuildContext(profile);

        // Get user's last message from chat
        string userMessage = UIChat.Instance?.GetLastUserMessage() ?? "Who are you?";

        // Start streaming response
        if (LLMStreamManager.Instance != null)
        {
            StartCoroutine(LLMStreamManager.Instance.StreamSpiritSpeech(context, userMessage));
        }
        else
        {
            // Fallback to non-streaming
            StartCoroutine(SendChatRequest(context, userMessage));
        }
    }

    /// <summary>
    /// Builds the full context prompt for the LLM.
    /// </summary>
    private string BuildContext(SpiritProfile profile)
    {
        // Load story text
        string storyText = LoadStoryText(profile.story);

        // Load memory if available
        SpiritMemory memory = SpiritMemory.Load(ActiveSpirit);
        string memoryContext = "";
        if (memory != null && memory.lastResponses != null && memory.lastResponses.Length > 0)
        {
            memoryContext = "\n\nPrevious encounters: " + string.Join(" ", memory.lastResponses);
        }

        // Build full prompt
        string fullPrompt = $"{profile.prompt}\n\n" +
                           $"Story context (excerpt):\n{storyText}\n" +
                           $"{memoryContext}\n\n" +
                           "Respond in character, eerily and poetically. Keep responses under 100 words.";

        return fullPrompt;
    }

    /// <summary>
    /// Loads story text from cache or StreamingAssets.
    /// Uses cached version if available to avoid blocking I/O.
    /// </summary>
    private string LoadStoryText(string storyFile)
    {
        // Check cache first
        if (cachedStories.TryGetValue(storyFile, out string cachedText))
        {
            return cachedText;
        }

        // Fallback to synchronous load if not cached (e.g., during preload)
        string storyPath = Path.Combine(Application.streamingAssetsPath, "PoeStories", storyFile);

        if (File.Exists(storyPath))
        {
            string fullText = File.ReadAllText(storyPath);
            // Truncate to max context length
            int truncateLength = Mathf.Min(fullText.Length, maxContextLength);
            string truncatedText = fullText.Substring(0, truncateLength);

            // Cache for future use
            cachedStories[storyFile] = truncatedText;

            return truncatedText;
        }
        else
        {
            Debug.LogWarning($"[LLMManager] Story file not found: {storyPath}");
            return "The story fades from memory, yet the spirit remains...";
        }
    }

    /// <summary>
    /// Sends a chat request to the LLM (non-streaming fallback).
    /// </summary>
    private IEnumerator SendChatRequest(string systemPrompt, string userMessage)
    {
        string fullPrompt = $"{systemPrompt}\n\nUser: {userMessage}\n\nSpirit:";

        // Create request body with consistent stop tokens
        string requestBody = JsonUtility.ToJson(new LLMRequest
        {
            prompt = fullPrompt,
            temperature = temperature,
            n_predict = maxTokens,
            stop = new string[] { "User:", "\n\n" }
        });

        using (UnityEngine.Networking.UnityWebRequest request = new UnityEngine.Networking.UnityWebRequest(llmEndpoint, "POST"))
        {
            byte[] bodyRaw = System.Text.Encoding.UTF8.GetBytes(requestBody);
            request.uploadHandler = new UnityEngine.Networking.UploadHandlerRaw(bodyRaw);
            request.downloadHandler = new UnityEngine.Networking.DownloadHandlerBuffer();
            request.SetRequestHeader("Content-Type", "application/json");
            request.timeout = 60; // Add timeout

            yield return request.SendWebRequest();

            if (request.result == UnityEngine.Networking.UnityWebRequest.Result.Success)
            {
                string response = request.downloadHandler.text;
                string responseContent = ParseLLMResponse(response);

                if (UIChat.Instance != null)
                {
                    UIChat.Instance.AppendResponse(responseContent);
                }

                // Parse emotion and react
                string emotion = EmotionParser.Detect(responseContent);
                if (EventManager.Instance != null)
                {
                    EventManager.Instance.ReactToEmotion(emotion);
                }

                // Save to memory
                SaveToMemory(userMessage, responseContent);
            }
            else
            {
                Debug.LogError($"[LLMManager] LLM request failed: {request.error}");
                if (UIChat.Instance != null)
                {
                    UIChat.Instance.AppendResponse("*The spirit's voice fades into static...*");
                }
            }
        }
    }

    /// <summary>
    /// Safely parses LLM response with robust null checking.
    /// </summary>
    private string ParseLLMResponse(string response)
    {
        if (string.IsNullOrEmpty(response))
        {
            return "*The spirit speaks in tongues incomprehensible...*";
        }

        try
        {
            LLMResponse llmResponse = JsonUtility.FromJson<LLMResponse>(response);

            // Check if parsing succeeded and content exists
            if (llmResponse != null && !string.IsNullOrEmpty(llmResponse.content))
            {
                return llmResponse.content;
            }

            // Try alternate response format (some LLMs use "text" or "response")
            LLMResponseAlt altResponse = JsonUtility.FromJson<LLMResponseAlt>(response);
            if (altResponse != null)
            {
                if (!string.IsNullOrEmpty(altResponse.text))
                    return altResponse.text;
                if (!string.IsNullOrEmpty(altResponse.response))
                    return altResponse.response;
            }
        }
        catch (System.Exception e)
        {
            Debug.LogWarning($"[LLMManager] Failed to parse LLM response as JSON: {e.Message}");
        }

        // If response looks like plain text (not JSON), use it directly
        string trimmed = response.Trim();
        if (!trimmed.StartsWith("{") && !trimmed.StartsWith("["))
        {
            return trimmed;
        }

        return "*The spirit speaks in tongues incomprehensible...*";
    }

    /// <summary>
    /// Saves the conversation exchange to spirit memory.
    /// </summary>
    public void SaveToMemory(string userMessage, string spiritResponse)
    {
        if (string.IsNullOrEmpty(ActiveSpirit)) return;

        SpiritMemory memory = SpiritMemory.Load(ActiveSpirit);
        memory.AddExchange(userMessage, spiritResponse);
        SpiritMemory.Save(memory);
    }

    /// <summary>
    /// Gets a random spirit key for variety.
    /// </summary>
    public string GetRandomSpiritKey()
    {
        string[] spirits = { "Raven", "Narrator", "Usher" };
        return spirits[Random.Range(0, spirits.Length)];
    }

    private void OnApplicationQuit()
    {
        // Ensure memory is saved
        if (!string.IsNullOrEmpty(ActiveSpirit))
        {
            Debug.Log("[LLMManager] Saving spirit memory on quit...");
        }
    }

    // Request/Response structures for JSON serialization
    [System.Serializable]
    private class LLMRequest
    {
        public string prompt;
        public float temperature;
        public int n_predict;
        public string[] stop;
    }

    [System.Serializable]
    private class LLMResponse
    {
        public string content;
    }

    // Alternate response format for compatibility with different LLM backends
    [System.Serializable]
    private class LLMResponseAlt
    {
        public string text;
        public string response;
    }

    private void OnDestroy()
    {
        // Clear singleton reference on destroy to prevent memory leaks
        if (Instance == this)
        {
            Instance = null;
        }
    }
}
